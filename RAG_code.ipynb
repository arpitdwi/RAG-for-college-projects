{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c26845d",
   "metadata": {},
   "source": [
    "# Langchain crash course"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f31c4cc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\arpitdwivedi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pydantic\\_internal\\_config.py:341: UserWarning: Valid config keys have changed in V2:\n",
      "* 'allow_population_by_field_name' has been renamed to 'populate_by_name'\n",
      "* 'smart_union' has been removed\n",
      "  warnings.warn(message, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_cohere import ChatCohere\n",
    "from langchain_cohere import CohereEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "os.environ['COHERE_API_KEY'] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11561034",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatCohere(model=\"command-r-plus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "767eb308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total documents loaded: 49\n"
     ]
    }
   ],
   "source": [
    "file_paths = [\"./data/MTP_Thesis_ArpitDwivedi.pdf\", \"./data/NLP_Report.pdf\", \"./data/MIES TERM PROJECT REPORT.pdf\"]\n",
    "\n",
    "# Initialize an empty list to store all documents\n",
    "docs = []\n",
    "\n",
    "# Loop through the file paths and load each PDF\n",
    "for file_path in file_paths:\n",
    "    loader = PyPDFLoader(file_path)\n",
    "    d = loader.load()\n",
    "    docs.extend(d)  # Add the documents to the list\n",
    "\n",
    "print(f\"Total documents loaded: {len(docs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86e1d6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cohere_embeddings = CohereEmbeddings(\n",
    "    model=\"embed-english-v3.0\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6445f71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200) #Split text, embed it and then store in vector store\n",
    "splits = text_splitter.split_documents(docs)\n",
    "vectorstore = Chroma.from_documents(documents=splits, embedding=cohere_embeddings)\n",
    "\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db32fa9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = (\n",
    "    \"You are an assistant for question-answering tasks. \"\n",
    "    \"Use the following pieces of retrieved context to answer \"\n",
    "    \"the question. If you don't know the answer, say that you \"\n",
    "    \"don't know. Use three sentences maximum and keep the \"\n",
    "    \"answer concise.\"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\"\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "question_answer_chain = create_stuff_documents_chain(model, prompt)\n",
    "rag_chain = create_retrieval_chain(retriever, question_answer_chain)\n",
    "\n",
    "results = rag_chain.invoke({\"input\": \"Does the ESIM model have better retrieval metrics or BERT? What is the Recall@10 for both?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4b09b75d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The BERT model has better retrieval metrics. The Recall@10 for ESIM is 81.30% and for BERT is 93.27%.\n"
     ]
    }
   ],
   "source": [
    "print(results['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ec426c5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The project aims to design an algorithm to distinguish imposters from authentic users based on mouse dynamics data. It uses self-organizing maps for unsupervised machine learning and can prevent security breaches. The conclusion states that these maps are effective tools for authentication when combined with supervised algorithms.\n",
      "The model architecture used was an ensemble method, combining six mBERT models and an artificial neural network (ANN) to output an overall similarity score.\n"
     ]
    }
   ],
   "source": [
    "#Other examples\n",
    "print(rag_chain.invoke({\"input\": \"Can you summarise the imposter detection project in 3 lines?\"})['answer'])\n",
    "print(rag_chain.invoke({\"input\": \"What was the model architecture used for multilingual news article similarity measurement?\"})['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a805451",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
